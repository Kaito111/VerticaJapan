{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data dictionary and source information\n",
    "\n",
    "Smart Meter data from the Irish Energy public dataset capturing kw readings \n",
    "every 15 minutes on thousands of residential and business meters 24 hrs a day\n",
    "http://www.ucd.ie/issda/data/commissionforenergyregulationcer/\n",
    "Weather data was also captured to correalte with kw readings\n",
    "\n",
    "--------------------------------------------------------------------------\n",
    "SQL to load the data should you need to do so\n",
    "\n",
    "CREATE TABLE sm_consumption\n",
    "(\n",
    "    meterID int,\n",
    "    dateUTC timestamp,\n",
    "    value numeric(25,5)\n",
    ");\n",
    "\n",
    "\n",
    "CREATE TABLE sm_weather\n",
    "(\n",
    "    dateUTC timestamp,\n",
    "    temperature numeric(25,5),\n",
    "    humidity numeric(25,5)\n",
    ");\n",
    "\n",
    "CREATE TABLE sm_meters\n",
    "(\n",
    "    meterID int NOT NULL,\n",
    "    residenceType int NOT NULL,\n",
    "    latitude numeric(25,15) NOT NULL,\n",
    "    longitude numeric(25,15) NOT NULL\n",
    ");\n",
    "\n",
    "CREATE TABLE sm_residences\n",
    "(\n",
    "    id int NOT NULL,\n",
    "    description varchar(15) NOT NULL\n",
    ");\n",
    "\n",
    "copy sm_consumption FROM '/home/dbadmin/sm_consumption.csv' delimiter ',';\n",
    "\n",
    "copy sm_weather FROM '/home/dbadmin/sm_weather.csv' delimiter ',';\n",
    "\n",
    "copy sm_meters FROM '/home/dbadmin/sm_meters.csv' delimiter ',';\n",
    "\n",
    "copy sm_residences FROM '/home/dbadmin/sm_residences.csv' delimiter ',';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information on using sqlalchemy to run SQL in jupyter with Vertica\n",
    "\n",
    "You will need sql alchemy 1.1.11 or higher before installing sqlalchemy-vertica\n",
    "\n",
    "Run\n",
    "\n",
    "    conda update sqlalchemy\n",
    "\n",
    "This updates sqlalchemy if you used Anaconda to install your python environment\n",
    "\n",
    "To install sqlalchemy-vertica run\n",
    "\n",
    "    pip install sqlalchemy-vertica[pyodbc,vertica-python]\n",
    "\n",
    "There are a lot of dependencies like psycopg2 and six and pyodbc\n",
    "\n",
    "Anancoda will take care of most of these\n",
    "\n",
    "Look at the error log if you did not use Anaconda and need to install the dependencies manually\n",
    "\n",
    "You may need to install pyodbc manually by running\n",
    "\n",
    "    pip install pyodbc\n",
    "\n",
    "After sqlalchemy-vertica is installed ensure ipython-sql is installed by running\n",
    "\n",
    "    pip install ipython-sql "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlalchemy as sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = \"vertica+pyodbc://dbadmin:vertica@VerticaDSN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sa.create_engine(conn, pool_size=10, max_overflow=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%sql vertica+pyodbc://VerticaDSN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------DATA EXPLORATION--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## system info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%sql select version();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%sql select * from nodes;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## view the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%sql select * from sm_consumption limit 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%sql select * from sm_weather limit 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%sql select * from sm_residences;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import mpl_toolkits.basemap\n",
    "from mpl_toolkits.basemap import Basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "austin = (-97.75, 30.25)\n",
    "hawaii = (-157.8, 21.3)\n",
    "washington = (-77.01, 38.90)\n",
    "chicago = (-87.68, 41.83)\n",
    "losangeles = (-118.25, 34.05)\n",
    "\n",
    "m = Basemap(projection = 'merc', llcrnrlat=10, urcrnrlat=50,\n",
    "        llcrnrlon=-160, urcrnrlon=-60)\n",
    "\n",
    "m.drawcoastlines()\n",
    "m.fillcontinents (color='lightgray', lake_color='lightblue')\n",
    "m.drawparallels(np.arange(-90.,91.,30.))\n",
    "m.drawmeridians(np.arange(-180.,181.,60.))\n",
    "m.drawmapboundary(fill_color='aqua')\n",
    "\n",
    "m.drawcounties()\n",
    "\n",
    "x, y = m(*zip(*[hawaii, austin, washington, chicago, losangeles]))\n",
    "m.plot(x,y, marker ='o', markersize=6, markerfacecolor='red', linewidth=0)\n",
    "\n",
    "plt.title('Mercator Projection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(\"select meterid, value, dateUTC from sm_consumption where meterid < 3;\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(df.value, bins=100)\n",
    "plt.xlim(0,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "\n",
    "df.groupby(['dateUTC','meterid']).max()['value'].unstack().plot(ax=ax)\n",
    "plt.ylim(0,15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## table count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%sql select count(*) from sm_consumption;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------FEATURE CREATION--------------------\n",
    "\n",
    "## Flag outliers with DETECT_OUTLIERS\n",
    "\n",
    "## use robust zscore with threshold of 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql \n",
    "drop table if exists sm_outliers cascade;\n",
    "SELECT DETECT_OUTLIERS('sm_outliers', 'sm_consumption', 'value', 'robust_zscore' \n",
    "    USING PARAMETERS outlier_threshold=3.0, key_columns='meterid, dateUTC');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save an outliers field\n",
    "\n",
    "## create a sequence for R UDX model scoring later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql \n",
    "drop sequence if exists seq;\n",
    "CREATE SEQUENCE seq;\n",
    "\n",
    "drop table if exists sm_consumption_outliers;\n",
    "create table sm_consumption_outliers as\n",
    "    select nextval('seq') as id, c.*, case when o.value is null then 0 else 1 end as highusage\n",
    "    from sm_consumption c left outer join sm_outliers o on c.meterid=o.meterid and c.dateUTC=o.dateUTC;\n",
    "\n",
    "drop view if exists sm_outliers;\n",
    "\n",
    "select * from sm_consumption_outliers where highusage = 1 limit 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create clusters of meterids based on kmeans distances \n",
    "\n",
    "## allows for new meter locations to be added and assigned a location id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop model if exists sm_kmeans;\n",
    "select kmeans('sm_kmeans', 'sm_meters', 'latitude, longitude', 6);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## look at results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%sql select summarize_model('sm_kmeans');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use apply_kmeans to score on a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists sm_meters_location;\n",
    "CREATE TABLE sm_meters_location AS\n",
    "        SELECT meterid, residenceType, latitude, longitude,\n",
    "        APPLY_KMEANS(latitude, longitude USING PARAMETERS model_name='sm_kmeans') AS locationid\n",
    "        FROM sm_meters;\n",
    "        \n",
    "select * from sm_meters_location limit 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fill in the weather gaps with GFI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## look at date intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select distinct cdate, wdate, temperature, humidity \n",
    "    from \n",
    "    (SELECT c.meterid, c.dateUTC as cdate, w.dateUTC as wdate, w.temperature, w.humidity, c.value\n",
    "    FROM  sm_consumption c left outer join sm_weather w on c.dateUTC = w.dateUTC order by cdate) a \n",
    "    order by 1 limit 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use TS_FRIST_VALUE to fill in the gaps\n",
    "\n",
    "## then look at the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists sm_weather_fill;\n",
    "create table sm_weather_fill as \n",
    "SELECT ts as dateUTC, \n",
    "    TS_FIRST_VALUE(temperature, 'LINEAR') temperature, \n",
    "    TS_FIRST_VALUE(humidity, 'LINEAR') humidity \n",
    "    FROM sm_weather\n",
    "    TIMESERIES ts AS '15 minutes' OVER (ORDER BY dateUTC);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select distinct cdate, wdate, temperature, humidity \n",
    "    from \n",
    "    (SELECT c.meterid, c.dateUTC as cdate, w.dateUTC as wdate, w.temperature, w.humidity, c.value\n",
    "    FROM  sm_consumption c left outer join sm_weather_fill w on c.dateUTC = w.dateUTC order by cdate) a \n",
    "    order by 1 limit 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create one large flat table from the four source tables with some new fields to help prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists sm_flat_pre;\n",
    "create table sm_flat_pre as\n",
    "    select  c.id, c.meterid, r.description as metertype, l.latitude, l.longitude, \n",
    "        l.locationid::varchar, dayofweek(c.dateUTC)::varchar as 'DOW',                 \n",
    "\n",
    "        case when month(c.dateUTC) >= 3 and month(c.dateUTC) <= 5 then 'Spring' \n",
    "            when month(c.dateUTC) >= 6 and month(c.dateUTC) <= 8 then 'Summer' \n",
    "            when month(c.dateUTC) >= 9 and month(c.dateUTC) <= 11 then 'Fall' \n",
    "            else 'Winter' end as 'Season',                \n",
    "                \n",
    "        case when hour(c.dateUTC) >= 6 and hour(c.dateUTC) <= 11 then 'Morning'\n",
    "            when hour(c.dateUTC) >= 12 and hour(c.dateUTC) <= 17 then 'Afternoon'\n",
    "            when hour(c.dateUTC) >= 18 and hour(c.dateUTC) <= 23 then 'Evening' \n",
    "            else 'Night' end as 'TOD',                \n",
    "               \n",
    "        w.temperature, w.humidity, c.highusage, c.highusage::varchar as highusage_char, c.value,\n",
    "                \n",
    "        case when random() < 0.3 then 'test' else 'train' end as part\n",
    "                \n",
    "    from sm_consumption_outliers c \n",
    "        inner join sm_meters_location l on c.meterid = l.meterid \n",
    "        inner join sm_residences r on l.residenceType = r.id\n",
    "        inner join sm_weather_fill w on c.dateUTC = w.dateUTC;\n",
    "        \n",
    "select * from sm_flat_pre limit 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normalize humidity and temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop model if exists sm_normfit;\n",
    "SELECT NORMALIZE_FIT('sm_normfit', 'sm_flat_pre', 'humidity, temperature', 'zscore');\n",
    "\n",
    "select summarize_model('sm_normfit');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one hot encoding fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop model if exists sm_ohe;\n",
    "SELECT ONE_HOT_ENCODER_FIT ('sm_ohe','sm_flat_pre','metertype, locationid, DOW, Season, TOD');\n",
    "\n",
    "select summarize_model('sm_ohe');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## apply one hot encoding and normalization in one step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists sm_flat;\n",
    "create table sm_flat as\n",
    "    select APPLY_ONE_HOT_ENCODER(* USING PARAMETERS model_name='sm_ohe')\n",
    "    FROM \n",
    "        (SELECT APPLY_NORMALIZE (* USING PARAMETERS model_name = 'sm_normfit') FROM sm_flat_pre) a;\n",
    "\n",
    "select * from sm_flat limit 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%sql select * from sm_flat limit 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename encoded columns\n",
    "##### Plus we need to run an extra step for OHE as there is a bug which won't let date-time cols pass through. This will be fixed in future release. Use this workaround for now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "ALTER TABLE sm_flat\n",
    "    RENAME COLUMN metertype_1 TO multi_family;\n",
    "ALTER TABLE sm_flat\n",
    "    RENAME COLUMN metertype_2 TO single_family;\n",
    "ALTER TABLE sm_flat\n",
    "    RENAME COLUMN locationid_1 TO loc1;\n",
    "ALTER TABLE sm_flat\n",
    "    RENAME COLUMN locationid_2 TO loc2;\n",
    "ALTER TABLE sm_flat\n",
    "    RENAME COLUMN locationid_3 TO loc3;\n",
    "ALTER TABLE sm_flat\n",
    "    RENAME COLUMN locationid_4 TO loc4;\n",
    "ALTER TABLE sm_flat\n",
    "    RENAME COLUMN locationid_5 TO loc5;\n",
    "ALTER TABLE sm_flat\n",
    "    RENAME COLUMN dow_1 TO monday;\n",
    "ALTER TABLE sm_flat\n",
    "    RENAME COLUMN dow_2 TO tuesday;\n",
    "ALTER TABLE sm_flat\n",
    "    RENAME COLUMN dow_3 TO wednesday;\n",
    "ALTER TABLE sm_flat\n",
    "    RENAME COLUMN dow_4 TO thursday;\n",
    "ALTER TABLE sm_flat\n",
    "    RENAME COLUMN dow_5 TO friday;\n",
    "ALTER TABLE sm_flat\n",
    "    RENAME COLUMN dow_6 TO saturday;\n",
    "ALTER TABLE sm_flat\n",
    "    RENAME COLUMN season_1 TO spring;\n",
    "ALTER TABLE sm_flat\n",
    "    RENAME COLUMN season_2 TO summer;\n",
    "ALTER TABLE sm_flat\n",
    "    RENAME COLUMN season_3 TO winter;\n",
    "    ALTER TABLE sm_flat\n",
    "    RENAME COLUMN tod_1 TO evening;\n",
    "ALTER TABLE sm_flat\n",
    "    RENAME COLUMN tod_2 TO morning;\n",
    "ALTER TABLE sm_flat\n",
    "    RENAME COLUMN tod_3 TO night;\n",
    "\n",
    "drop table if exists sm_flat_tmp cascade;\n",
    "create table sm_flat_tmp as select * from sm_flat;\n",
    "\n",
    "drop table if exists sm_flat cascade;\n",
    "create table sm_flat as select c.dateUTC, f.* from sm_flat_tmp f\n",
    "inner join sm_consumption_outliers c on f.id = c.id;\n",
    "\n",
    "drop table if exists sm_flat_tmp cascade;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------PREDICTIVE MODELING--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train and test\n",
    "## we need a table or view with just the training data for modeling\n",
    "## we can score it on sm_flat and then use where part='test'\n",
    "## when we want to look at the test results only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists sm_flat_train;\n",
    "create table sm_flat_train as \n",
    "    select * from sm_flat where part='train';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----BUILD ALL THE MODELS-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop model if exists sm_linear;\n",
    "select linear_reg('sm_linear', 'sm_flat_train', 'value', \n",
    "'multi_family, single_family, loc1, loc2, loc3, loc4, loc5, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, \n",
    "winter, Summer, spring, night, morning, Evening, temperature, humidity');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop model if exists sm_svm_reg;\n",
    "select SVM_REGRESSOR('sm_svm_reg', 'sm_flat_train', 'value', \n",
    "'multi_family, single_family, loc1, loc2, loc3, loc4, loc5, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, \n",
    "winter, Summer, spring, night, morning, Evening, temperature, humidity');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop model if exists sm_rf_reg;\n",
    "select rf_regressor('sm_rf_reg', 'sm_flat_train', 'value', \n",
    "'metertype, locationid, DOW, Season, TOD, temperature, humidity');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop model if exists sm_logistic;\n",
    "select logistic_reg('sm_logistic', 'sm_flat_train', 'highusage', \n",
    "'multi_family, single_family, loc1, loc2, loc3, loc4, loc5, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, \n",
    "winter, Summer, spring, night, morning, Evening, temperature, humidity');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop model if exists sm_nb;\n",
    "select naive_bayes('sm_nb', 'sm_flat_train', 'highusage', \n",
    "'multi_family, single_family, loc1, loc2, loc3, loc4, loc5, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, \n",
    "winter, Summer, spring, night, morning, Evening, temperature, humidity');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM CLASSIFICATION\n",
    "\n",
    "### svm is a decision boundary optimizer and does not produce probabilities so we must balance the data first\n",
    "\n",
    "### Balance the data and then view the old and new dependent variable rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop view if exists sm_flat_train_balanced;\n",
    "select BALANCE ( 'sm_flat_train_balanced', 'sm_flat_train', 'highusage', 'over_sampling'\n",
    "    USING PARAMETERS sampling_ratio=0.6 );\n",
    "            \n",
    "select avg(highusage) from sm_flat_train union\n",
    "select avg(highusage) from sm_flat_train_balanced;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop model if exists sm_svm;\n",
    "select svm_classifier('sm_svm', 'sm_flat_train_balanced', 'highusage', \n",
    "'multi_family, single_family, loc1, loc2, loc3, loc4, loc5, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, \n",
    "winter, Summer, spring, night, morning, Evening, temperature, humidity');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF CLASSIFICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop model if exists sm_rf;\n",
    "select rf_classifier('sm_rf', 'sm_flat_train', 'highusage_char', \n",
    "'metertype, locationid, DOW, Season, TOD, temperature, humidity');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now take a look at the models created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%sql select * from models;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF CLASSIFIER USING R\n",
    "\n",
    "##### Before running this you must install the random forest library on each instance of R that is running on every node in your Vertica cluster. Older versions of Vertica came with R installed automatically. Newer versions of Vertica may require you to install the Vertica-R-package manually (due to legal reasons). You can find vertica-R-package at https://my.vertica.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP library IF EXISTS rflib CASCADE;\n",
    "CREATE library rflib AS '/home/dbadmin/R_UDX/randomforest/rf_udf.R' LANGUAGE 'R';\n",
    "CREATE transform FUNCTION rf_build_udf AS LANGUAGE 'R' name 'rf_build_factory' library rflib;\n",
    "CREATE transform FUNCTION rf_score_udf AS LANGUAGE 'R' name 'rf_score_factory' library rflib;\n",
    "\n",
    "SELECT\n",
    "rf_build_udf(\"highusage_char\", \"metertype\", \"locationid\", \"Season\", \"DOW\", \"TOD\", \"temperature\", \"humidity\" \n",
    "using parameters append_date=1, model_name='my_rf_model', model_folder='/home/dbadmin')\n",
    "over () \n",
    "FROM sm_flat_train;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score all the models and save results in a table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run rf_score_udf\n",
    "### stores id, prediciton, and probability in a table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first score the R model as that needs to be done separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists sm_pred_rfudx cascade;\n",
    "create table sm_pred_rfudx as SELECT \n",
    "rf_score_udf(\"id\", \"highusage_char\", \"metertype\", \"locationid\", \"Season\", \"DOW\", \"TOD\", \"temperature\", \"humidity\" \n",
    "using parameters model='/home/dbadmin/my_rf_model-2018-03-05-15-25-06.rda')\n",
    "over () \n",
    "FROM sm_flat;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now score all the Vertica models in one create table statement using each model's predict function, and join in the R results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists sm_flat_pred;\n",
    "CREATE TABLE sm_flat_pred AS \n",
    "(SELECT a.*, \n",
    "\n",
    "        PREDICT_linear_REG(multi_family, single_family, loc1, loc2, loc3, loc4, loc5, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, \n",
    "                winter, Summer, spring, night, morning, Evening, temperature, humidity \n",
    "                USING PARAMETERS model_name='sm_linear') as lin_reg_pred, \n",
    "                \n",
    "        PREDICT_SVM_REGRESSOR(multi_family, single_family, loc1, loc2, loc3, loc4, loc5, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, \n",
    "                winter, Summer, spring, night, morning, Evening, temperature, humidity \n",
    "                USING PARAMETERS model_name='sm_svm_reg') as svm_reg_pred,\n",
    "                \n",
    "        predict_rf_regressor(metertype, locationid, DOW, Season, TOD, temperature, humidity \n",
    "                USING PARAMETERS model_name='sm_rf_reg') as rf_reg_pred, \n",
    "                \n",
    "        PREDICT_LOGISTIC_REG(multi_family, single_family, loc1, loc2, loc3, loc4, loc5, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, \n",
    "                winter, Summer, spring, night, morning, Evening, temperature, humidity \n",
    "                USING PARAMETERS model_name='sm_logistic', type='probability') AS log_reg_prob, \n",
    "        \n",
    "        PREDICT_LOGISTIC_REG(multi_family, single_family, loc1, loc2, loc3, loc4, loc5, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, \n",
    "                winter, Summer, spring, night, morning, Evening, temperature, humidity  \n",
    "                USING PARAMETERS model_name='sm_logistic', type = 'response') AS log_reg_pred,  \n",
    "        \n",
    "        PREDICT_LOGISTIC_REG(multi_family, single_family, loc1, loc2, loc3, loc4, loc5, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, \n",
    "                winter, Summer, spring, night, morning, Evening, temperature, humidity  \n",
    "                USING PARAMETERS model_name='sm_logistic', cutoff='0.15') AS log_reg_pred15  ,\n",
    "                \n",
    "        PREDICT_NAIVE_BAYES (multi_family, single_family, loc1, loc2, loc3, loc4, loc5, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, \n",
    "                winter, Summer, spring, night, morning, Evening, temperature, humidity\n",
    "                USING PARAMETERS model_name = 'sm_nb',type = 'probability', class='1')::float AS nb_prob, \n",
    "        \n",
    "        PREDICT_NAIVE_BAYES (multi_family, single_family, loc1, loc2, loc3, loc4, loc5, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, \n",
    "                winter, Summer, spring, night, morning, Evening, temperature, humidity\n",
    "                USING PARAMETERS model_name = 'sm_nb',type = 'response') AS nb_pred, \n",
    "        \n",
    "        case when PREDICT_NAIVE_BAYES (multi_family, single_family, loc1, loc2, loc3, loc4, loc5, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, \n",
    "                winter, Summer, spring, night, morning, Evening, temperature, humidity\n",
    "                USING PARAMETERS model_name = 'sm_nb',type = 'probability', class='1')::float > 0.15 then 1 else 0 end AS nb_pred15,\n",
    "                \n",
    "        PREDICT_RF_CLASSIFIER (metertype, locationid, DOW, Season, TOD, temperature, humidity\n",
    "                USING PARAMETERS model_name = 'sm_rf',type = 'probability', class='1')::float AS rf_class_prob, \n",
    "        \n",
    "        PREDICT_RF_CLASSIFIER (metertype, locationid, DOW, Season, TOD, temperature, humidity\n",
    "                USING PARAMETERS model_name = 'sm_rf',type = 'response') AS rf_class_pred, \n",
    "        \n",
    "        case when PREDICT_RF_CLASSIFIER (metertype, locationid, DOW, Season, TOD, temperature, humidity\n",
    "                USING PARAMETERS model_name = 'sm_rf',type = 'probability', class='1')::float > 0.15 then 1 else 0 end AS rf_class_pred15,\n",
    "        \n",
    "        case when b.pred = '0' then 1 - b.maxprob else b.maxprob end as r_rf_class_prob,\n",
    "        case when b.pred = '1' or (b.pred = '0' and b.maxprob <= 0.85) then 1 else 0 end as r_rf_class_pred15\n",
    "        \n",
    "FROM sm_flat a inner join sm_pred_rfudx b on a.id = b.id);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----MODEL SUMMARIES-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%sql SELECT SUMMARIZE_MODEL('sm_linear');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%sql SELECT SUMMARIZE_MODEL('sm_svm_reg');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%sql SELECT SUMMARIZE_MODEL('sm_rf_reg');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%sql SELECT SUMMARIZE_MODEL('sm_logistic');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%sql SELECT SUMMARIZE_MODEL('sm_nb');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%sql SELECT SUMMARIZE_MODEL('sm_svm');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%sql SELECT SUMMARIZE_MODEL('sm_rf');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save model stats in a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists sm_linear_sum;\n",
    "create table sm_linear_sum as SELECT GET_MODEL_ATTRIBUTE \n",
    "(USING PARAMETERS model_name='sm_linear', attr_name = 'details');\n",
    "\n",
    "select * from sm_linear_sum;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----MODEL METRICS-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%sql select MSE (value, lin_reg_pred) over() from sm_flat_pred where part = 'test';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%sql select corr(value, lin_reg_pred)^2 as r_square from sm_flat_pred where part = 'test';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT ERROR_RATE(obs, pred::int USING PARAMETERS num_classes=2) OVER() \n",
    "FROM (SELECT highusage AS obs, log_reg_pred15 AS pred FROM sm_flat_pred where part = 'test') a;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql \n",
    "SELECT ROC(obs::int, prob::float USING PARAMETERS num_bins=20) OVER() \n",
    "FROM (SELECT highusage AS obs, log_reg_prob as prob FROM sm_flat_pred where part='test') a;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql \n",
    "SELECT CONFUSION_MATRIX(obs::int, pred::int USING PARAMETERS num_classes=2) OVER() \n",
    "FROM (SELECT highusage AS obs, log_reg_pred15 as pred FROM sm_flat_pred where part = 'test') AS prediction_output;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----COMPARE MODEL AUC-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists AUC_comp cascade;\n",
    "CREATE TABLE AUC_comp\n",
    "(\n",
    "    model varchar(50),\n",
    "    AUC float\n",
    ");\n",
    "\n",
    "insert into AUC_comp\n",
    "select 'logistic' as model, \n",
    "sum((true_positive_rate+prev_tpr)*(prev_fpr - false_positive_rate)/2) as AUC from \n",
    "(\n",
    "        select lag(true_positive_rate) over (order by false_positive_rate desc) as prev_tpr, \n",
    "                lag(false_positive_rate) over (order by false_positive_rate desc) as prev_fpr, * from \n",
    "        (\n",
    "                select false_positive_rate, avg(true_positive_rate) as true_positive_rate from\n",
    "                (\n",
    "                SELECT ROC(obs::int, prob::float USING PARAMETERS num_bins=1000) OVER() \n",
    "                FROM (SELECT highusage AS obs, log_reg_prob as prob FROM sm_flat_pred where part='test') AS prediction_output \n",
    "                ) q1 group by false_positive_rate  \n",
    "        ) q2 \n",
    ") q3;\n",
    "\n",
    "insert into AUC_comp\n",
    "select 'nb' as model, \n",
    "sum((true_positive_rate+prev_tpr)*(prev_fpr - false_positive_rate)/2) as AUC from \n",
    "(\n",
    "        select lag(true_positive_rate) over (order by false_positive_rate desc) as prev_tpr, \n",
    "                lag(false_positive_rate) over (order by false_positive_rate desc) as prev_fpr, * from \n",
    "        (\n",
    "                select false_positive_rate, avg(true_positive_rate) as true_positive_rate from\n",
    "                (\n",
    "                SELECT ROC(obs::int, prob::float USING PARAMETERS num_bins=1000) OVER() \n",
    "                FROM (SELECT highusage AS obs, nb_prob as prob FROM sm_flat_pred where part='test') AS prediction_output \n",
    "                ) q1 group by false_positive_rate  \n",
    "        ) q2 \n",
    ") q3;\n",
    "\n",
    "insert into AUC_comp\n",
    "select 'rf' as model, \n",
    "sum((true_positive_rate+prev_tpr)*(prev_fpr - false_positive_rate)/2) as AUC from \n",
    "(\n",
    "        select lag(true_positive_rate) over (order by false_positive_rate desc) as prev_tpr, \n",
    "                lag(false_positive_rate) over (order by false_positive_rate desc) as prev_fpr, * from \n",
    "        (\n",
    "                select false_positive_rate, avg(true_positive_rate) as true_positive_rate from\n",
    "                (\n",
    "                SELECT ROC(obs::int, prob::float USING PARAMETERS num_bins=1000) OVER() \n",
    "                FROM (SELECT highusage AS obs, rf_class_prob as prob FROM sm_flat_pred where part='test') AS prediction_output \n",
    "                ) q1 group by false_positive_rate  \n",
    "        ) q2 \n",
    ") q3;\n",
    "\n",
    "insert into AUC_comp\n",
    "select 'rfudx' as model, \n",
    "sum((true_positive_rate+prev_tpr)*(prev_fpr - false_positive_rate)/2) as AUC from \n",
    "(\n",
    "        select lag(true_positive_rate) over (order by false_positive_rate desc) as prev_tpr, \n",
    "                lag(false_positive_rate) over (order by false_positive_rate desc) as prev_fpr, * from \n",
    "        (\n",
    "                select false_positive_rate, avg(true_positive_rate) as true_positive_rate from\n",
    "                (\n",
    "                SELECT ROC(obs::int, prob::float USING PARAMETERS num_bins=1000) OVER() \n",
    "                FROM (SELECT highusage AS obs, r_rf_class_prob as prob FROM sm_flat_pred where part='test') AS prediction_output \n",
    "                ) q1 group by false_positive_rate  \n",
    "        ) q2 \n",
    ") q3;\n",
    "\n",
    "select * from AUC_comp order by AUC desc;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----MORE MODEL MANAGEMENT-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export models to file\n",
    "\n",
    "#### SELECT EXPORT_MODELS ('/home/dbadmin/mlmodels', 'public.*')\n",
    "\n",
    "\n",
    "## Import models from file\n",
    "\n",
    "#### SELECT IMPORT_MODELS ('/home/dbadmin/mlmodels/*' USING PARAMETERS new_schema='public')\n",
    "\n",
    "\n",
    "## Upgrade models from a prior version\n",
    "\n",
    "#### SELECT UPGRADE_MODEL(USING PARAMETERS model_name = 'myLogisticRegModel');\n",
    "#### SELECT UPGRADE_MODEL();\n",
    "\n",
    "\n",
    "## Alter model metadata\n",
    "#### ALTER MODEL mymodel RENAME to mykmeansmodel;\n",
    "#### ALTER MODEL mykmeansmodel OWNER TO user1;\n",
    "#### ALTER MODEL mykmeansmodel SET SCHEMA public;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
